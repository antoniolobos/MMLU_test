# MMLU_test
For the test of LLMs on MMLU benchmark.

Usage:
```sh
python eval_mmlu.py --model [model-path] --save_dir [save-dir]
```

The results would be saved to `./mmlu_results` by default